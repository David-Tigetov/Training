\chapter{Преобразование случайных векторов}

\section*{Введение}
Пусть $\xi$ и $\eta$ --- случайные величины, и $a$, $b$ и $c$ --- числа, с помощью которых образуется случайная величина:
\begin{equation}
    \zeta = a \cdot \xi + b \cdot \eta + c,
\end{equation}
тогда:
\begin{equation}
    \expectation{\zeta}
    = \expectation{a \cdot \xi + b \cdot \eta + c}
    = a \cdot \expectation{\xi} + b \cdot \expectation{\eta} + c
\end{equation}
а для дисперсии справедливо равенство:
\begin{equation}
    \variance{\zeta}
    = \variance{a \cdot \xi + b \cdot \eta + c}
    = a^2 \cdot \variance{\xi} + b^2 \cdot \variance{\eta} + 2 a b \cdot \covariance{\xi}{\eta},
\end{equation}
где
\begin{multline}
    \label{10:covariance}
    \covariance{\xi}{\eta}
    = \expectation{\left ( \xi - \expectation{\xi} \right ) \left ( \eta - \expectation{\eta} \right )} = \\
    %
    = \expectation{ \xi \eta - \expectation{\xi} \eta - \xi \expectation{\eta} - \expectation{\xi} \expectation{\eta}} = \\
    %
    = \expectation{\xi\eta} - \expectation{\xi} \expectation{\eta} - \expectation{\xi} \expectation{\eta} + \expectation{\xi} \expectation{\eta} = \\
    %
    = \expectation{\xi\eta} - \expectation{\xi} \expectation{\eta}.
\end{multline}
Для \textbf{независимых} случайных величин:
\begin{equation}
    \covariance{\xi}{\eta}
    = \expectation{\left ( \xi - \expectation{\xi} \right ) \left ( \eta - \expectation{\eta} \right )}
    = \left ( \expectation{\xi} - \expectation{\xi} \right ) \left ( \expectation{\eta} - \expectation{\eta} \right )
    = 0 \cdot 0
    = 0 .
\end{equation}

Если $\zeta = \varphi(\xi, \eta)$, тогда:
\begin{equation}
    \expectation{\zeta^k}
    = \expectation{\varphi^k(\xi, \eta)}
    = \left [
            \begin{array}{l}
                \sum \limits_{(x, y)} \varphi^k(x,y) \probability{\xi = x, \eta = y} , \\
                \iint \limits_{\mathbb{R}^2} \varphi^k(x,y) f_{\xi, \eta}(x,y) dx dy
            \end{array}
    \right .
    ,
\end{equation}
где $f_{\xi,\eta}(x,y)$ --- совместная плотность вероятности случайных величин $\xi$ и $\eta$.

В некоторых случаях, удобно использовать условное математическое ожидание:
\begin{equation}
    \expectation{\zeta^k}
    = \expectation{\expectation{\condition{\zeta^k}{\xi}}} .
\end{equation}

Функция распределения $F_\zeta(z)$ случайной величины $\zeta$:
\begin{equation}
    F_{\zeta}(z)
    = \probability{\zeta < z}
    = \probability{\varphi(\xi, \eta) < z}
    = \left [
            \begin{array}{l}
                \sum \limits_{x + y < z} \probability{\xi = x, \eta = y} , \\
                \iint \limits_{x + y < z} f_{\xi, \eta}(x, y) dx dy
            \end{array}
    \right .
\end{equation}
Если $\zeta = \xi + \eta$, где $\xi$ и $\eta$ --- величины непрерывного типа, то функция плотности вероятности $f_\zeta(z)$ случайной величины $\zeta$:
\begin{equation}
    f_{\zeta}(z)
    = \int \limits_{-\infty}^{\infty} f_{\xi, \eta}(t, z-t) dt .
\end{equation}

\section*{Задача 18.437}

Случайные величины $X$ и $Y$ независимы и имеют следующие характеристики: $m_X = 1$, $m_Y = 2$, $\sigma_X = 1$, $\sigma_Y = 2$.
Вычислить математические ожидания случайных величин:
\begin{enumerate}
    \item $U = X^2 + 2 Y^2 - XY - 4X + Y + 4$,
    \item $V = (X + Y - 1)^2$
\end{enumerate}

\subsection*{Решение:}
\begin{enumerate}
    \item По свойству линейности математического ожидания:
    \begin{multline}
        \label{10:437:U}
        \expectation{U}
        = \expectation{X^2 + 2 Y^2 - XY - 4X + Y + 4} = \\
        = \expectation{X^2} + 2 \expectation{Y^2} - \expectation{XY} - 4 \expectation{X} + \expectation{Y} + \expectation{4}
    \end{multline}

    Для вычисления вторых начальных моментов используем известное соотношение для дисперсии:
    \begin{gather}
        \variance{X} = \expectation{X^2} - \left ( \expectation{X} \right )^2 , \\
        \variance{X} + \left ( \expectation{X} \right )^2 = \expectation{X^2} \label{10:437:X_2}.
    \end{gather}
    и
    \begin{equation}
        \label{10:437:Y_2}
        \expectation{Y^2} = \variance{Y} + \left ( \expectation{Y} \right )^2.
    \end{equation}

    По условию задачи величины $X$ и $Y$ \textbf{независимы}, поэтому:
    \begin{gather}
        \expectation{XY} = \expectation{X} \cdot \expectation{Y}
    \end{gather}

    Подставляя полученные выражения в равенство \eqref{10:437:U}, получим:
    \begin{multline}
        \expectation{U}
        = \variance{X} + \left ( \expectation{X} \right )^2 + 2 \left ( \variance{Y} + \left ( \expectation{Y} \right )^2 \right ) - \expectation{X} \cdot \expectation{Y} - 4 \expectation{X} + \expectation{Y} + \expectation{4} = \\
        = \sigma_X^2 + m_X^2 + 2 \left ( \sigma_Y^2 + m_Y^2 \right ) - m_X m_Y - 4 m_X + m_Y + 4 = \\
        = 1^2 + 1^2 + 2 \left ( 2^2 + 2^2 \right ) - 1 \cdot 2 - 4 \cdot 1 + 2 + 4 = 18
        .
    \end{multline}

    \item Заметим, что величина $V$ является квадратом выражения, и требуется найти второй начальный момент:
    \begin{equation}
        \label{10:437:expectation}
        \expectation{V} = \expectation{\left ( X + Y - 1 \right )^2} = \variance{X + Y - 1} + \left ( \expectation{X + Y - 1} \right )^2 ,
    \end{equation}
    где в последнем равенстве использовалось выражение для второго момента через дисперсию и квадрат математического ожидания, как ранее, в выражениях \eqref{10:437:X_2}
    и \eqref{10:437:Y_2}.
    По свойствам дисперсии:
    \begin{equation}
        \label{10:437:variance}
        \variance{X + Y - 1} = \variance{X} + \variance{Y} + 2 \covariance{X}{Y}
    \end{equation}
    Ковариация величин $X$ и $Y$ из равенства \eqref{10:covariance}:
    \begin{equation}
        \covariance{X}{Y} = \expectation{XY} - \expectation{X} \expectation{Y}.
    \end{equation}
    В силу \textbf{независимости} величин $X$ и $Y$:
    \begin{equation}
        \covariance{X}{Y} = 0 ,
    \end{equation}
    а выражение для дисперсии \eqref{10:437:variance} принимает вид:
    \begin{equation}
        \variance{X + Y - 1} = \variance{X} + \variance{Y} .
    \end{equation}
    и выражение \eqref{10:437:expectation}:
    \begin{multline}
        \expectation{V}
        = \variance{X} + \variance{Y} + \left ( \expectation{X} + \expectation{Y} - 1 \right )^2 = \\
        %
        = \sigma_X^2 + \sigma_Y^2 + \left ( m_X + m_Y - 1 \right )^2
        = 1^2
        + 2^2 + \left ( 1 + 2 - 1 \right )^2
        = 9.
    \end{multline}
\end{enumerate}

\subsection*{Ответ}
\begin{enumerate}
    \item $\expectation{U} = 18$ ,
    \item $\expectation{V} = 9$.
\end{enumerate}


\section*{Задача 18.438}

Случайная точка $\left ( X, Y \right )$ характеризуется центром рассеивания $(-1, 1)$ и ковариационной матрицей
$\begin{pmatrix}
     3  & -2 \\
     -2 & 4
\end{pmatrix}$.
Найти математическое ожидание и дисперсию случайной величины $Z = 2 X - 4 Y + 3$.

\subsection*{Решение:}

Центр рассеивания:
\begin{equation}
    \begin{pmatrix}
        -1 \\
        1
    \end{pmatrix}
    =
    \begin{pmatrix}
        \expectation{X} \\
        \expectation{Y}
    \end{pmatrix}
    .
\end{equation}

Ковариационная матрица
\begin{equation}
    \begin{pmatrix}
        3  & -2 \\
        -2 & 4
    \end{pmatrix}
    =
    \begin{pmatrix}
        \variance{X}      & \covariance{X}{Y} \\
        \covariance{X}{Y} & \variance{Y}
    \end{pmatrix}
    .
\end{equation}

В силу линейности математического ожидания:
\begin{equation}
    \expectation{Z}
    = \expectation{2X - 4 Y + 3}
    = 2 \expectation{X} - 4 \expectation{Y} + 3
    = 2 \cdot (-1) - 4 \cdot 1 + 3
    = -3
    .
\end{equation}
и по свойствам дисперсии:
\begin{multline}
    \variance{Z}
    = \variance{2 X - 4 Y + 3}
    = \variance{2 X + (-4) Y + 3} = \\
    %
    = 2^2 \cdot \variance{X} + (-4)^2 \cdot \variance{Y} + 2 \cdot 2 \cdot (-4) \cdot \covariance{X}{Y} = \\
    %
    = 4 \cdot 3 + 16 \cdot 4 - 16 \cdot (-2)
    = 12 + 16 \cdot 6
    = 12 + 96
    = 108.
\end{multline}

\subsection*{Ответ}
$\expectation{Z} = -3$, $\variance{Z} = 108$.

\section*{Задача 18.443}

Случайная величина $X$ дискретного типа распределена по закону, определяемому таблицей:

\begin{tabular}{|c|c|c|c|}
    \hline
    $x_i$ & -1            & 0             & 1             \\
    \hline
    $p_i$ & $\frac{1}{6}$ & $\frac{1}{3}$ & $\frac{1}{2}$ \\
    \hline
\end{tabular}

Найти коэффициент корреляции между $X$ и $X^2$.

\subsection*{Решение:}

По определению коэффициент корреляции $\rho$:
\begin{equation}
    \rho = \frac{\covariance{X}{X^2}}{\sqrt{\variance{X} \variance{X^2}}}
\end{equation}

Представим ковариацию с помощью моментов:
\begin{equation}
    \covariance{X}{X^2}
    = \expectation{X \cdot X^2} - \expectation{X} \cdot \expectation{X^2}
    = \expectation{X^3} - \expectation{X} \cdot \expectation{X^2}
\end{equation}

Заметим, что у величины $X$ начальные моменты нечётного порядка ($k=1,2,3,...$):
\begin{equation}
    \expectation{X^{2k-1}} = \sum_{i=1}^3 x_i^{2k-1} \cdot p_i = (-1)^{2k-1} \cdot \frac{1}{6} + 0^{2k-1} \cdot \frac{1}{3} + 1^{2k-1} \cdot \frac{1}{2} = - \frac{1}{6} + \frac{1}{2} = \frac{1}{3} ,
\end{equation}
и начальные моменты чётного порядка ($k=1,2,3,...$):
\begin{equation}
    \expectation{X^{2k}} = \sum_{i=1}^3 x_i^{2k} \cdot p_i = (-1)^{2k} \cdot \frac{1}{6} + 0^{2k} \cdot \frac{1}{3} + 1^{2k} \cdot \frac{1}{2} = \frac{1}{6} + \frac{1}{2} = \frac{2}{3} .
\end{equation}

Таким образом, ковариация:
\begin{equation}
    \covariance{X}{X^2} = \frac{1}{3} - \frac{1}{3} \cdot \frac{2}{3} = \frac{3}{9} - \frac{2}{9} = \frac{1}{9} .
\end{equation}

Вычислим дисперсии:
\begin{gather}
    \variance{X} = \expectation{X^2} - \left ( \expectation{X} \right )^2 = \frac{2}{3} - \left ( \frac{1}{3} \right )^2 = \frac{6}{9} - \frac{1}{9} = \frac{5}{9} , \\
    \variance{X^2} = \expectation{X^4} - \left ( \expectation{X^2} \right )^2 = \frac{2}{3} - \left ( \frac{2}{3} \right )^2 = \frac{6}{9} - \frac{4}{9} = \frac{2}{9}.
\end{gather}

Таким образом, коэффициент корреляции:
\begin{equation}
    \rho = \frac{\frac{1}{9}}{\sqrt{\frac{5}{9} \cdot \frac{2}{9}}} = \frac{\frac{1}{9}}{\frac{1}{9} \sqrt{10}} = \frac{1}{\sqrt{10}} .
\end{equation}

\subsection*{Ответ:}
$\frac{1}{\sqrt{10}}$.

\section*{Задача 18.450}

На окружность радиуса $r$ наудачу ставятся две точки. Найти математическое ожидание $\expectation{L}$ и дисперсию $\variance{L}$ случайной длины
$L$ хорды, соединяющей эти точки.

\subsection*{Решение:}

Пусть $\varphi$ обозначает центральный угол между радиусами, соединяющими центр окружности с точками, тогда длина хорды (рисунок \ref{10:450:hord}):
\begin{gather}
    L^2
    = r^2 + r^2 - 2 r^2 \cos \varphi
    = 2 r^2 \left ( 1 - \cos \varphi \right )
    = 2 r^2 \cdot 2 \frac{1 - \cos \varphi}{2}
    = 4 r^2 \sin^2 \frac{\varphi}{2} , \\
    %
    L
    = 2 r \sin \frac{\varphi}{2} ,
\end{gather}
где угол $\varphi$ имеет равномерное распределение $R \left [ 0, \pi \right ]$, поскольку точки на окружности выбираются наудачу.

\begin{figure}[!ht]
    \centering
    \begin{tikzpicture}[scale=3]
        % окружность
        \draw [dashed] ( 0, 0 ) circle [radius = 1];

        % координаты точек
        \def \Ax { 0.8 };
        \def \Ay { 0.6 };
        \def \Bx { -0.5 };
        \def \By { 0.866 };

        % точки
        \draw [fill] ( 0, 0 ) circle [radius = 0.02] node [below left] at ( 0, 0 ) {$O$};
        \draw [fill] ( \Ax, \Ay ) circle [radius = 0.02] node [above right] at ( \Ax, \Ay ) {$A$};
        \draw [fill] ( \Bx, \By ) circle [radius = 0.02] node [above left] at ( \Bx, \By ) {$B$};

        % радиусы
        \draw ( 0, 0 ) -- ( \Ax, \Ay );
        \draw ( 0, 0 ) -- ( \Bx, \By );

        % хорда
        \draw ( \Ax, \Ay ) -- ( \Bx, \By );

        % угол
        \node [above] at ( 0.03, 0 ) {$\varphi$};
        % длина
        \node [above] at ( 0.2, 0.75 ) {$L$};
    \end{tikzpicture}
    \caption{Окружность и хорда.}
    \label{10:450:hord}
\end{figure}

Таким образом, математическое ожидание:
\begin{multline}
    \expectation{L}
    = \expectation{2 r \sin \frac{\varphi}{2}}
    = 2 r \expectation{\sin \frac{\varphi}{2}} = \\
    %
    = 2 r \int \limits_0^\pi \sin \frac{x}{2} \frac{1}{\pi} d x
    = 2 r \frac{1}{\pi} \left . \left ( - 2 \cos \frac{x}{2} \right ) \right |_0^\pi
    = 2 r \frac{1}{\pi} 2
    = \frac{4 r}{\pi} .
\end{multline}

Второй начальный момент длины хорды:
\begin{multline}
    \expectation{L^2}
    = \expectation{\left ( 2 r \sin \frac{\varphi}{2} \right )^2}
    = \expectation{4 r^2 \sin^2 \frac{\varphi}{2}}
    = 4 r^2 \expectation{\sin^2 \frac{\varphi}{2}} = \\
    %
    = 4 r^2 \int \limits_0^\pi \sin^2 \frac{x}{2} \frac{1}{\pi} d x
    = 4 r^2 \int \limits_0^\pi \left ( \frac{1 - \cos x}{2} \right ) \frac{1}{\pi} d x
    = 4 r^2 \frac{1}{2 \pi} \int \limits_0^\pi \left ( 1 - \cos x \right ) d x = \\
    %
    = \frac{2 r^2}{\pi} \left . \left ( x - \sin x \right ) \right |_0^\pi
    = \frac{2 r^2}{\pi} \pi
    = 2 r^2 .
\end{multline}
Тогда дисперсия длины хорды:
\begin{equation}
    \variance{L}
    = \expectation{L^2} - \left ( \expectation{L} \right )^2
    = 2 r^2 - \frac{16 r^2}{\pi^2}
    = 2 r^2 \left ( 1 - \frac{8}{\pi^2} \right ).
\end{equation}

\subsection*{Ответ:}
$\expectation{L} = \frac{4 r}{\pi}$, $\variance{L} = 2 r^2 \left ( 1 - \frac{8}{\pi^2} \right )$.

\section*{Задача 18.463}
При броске игрального кубика выпало количество очков $X$. Производится ещё $X$ подбрасываний и фиксируется сумма всех выпавших очков $Z$.
Найти математическое ожидание $\expectation{Z}$ и дисперсию $\variance{Z}$.

\subsection*{Решение:}
Пусть $X_1$, \dots, $X_6$ обозначают количества очков, выпавших в результате второй части подбрасываний, тогда сумму очков $Z$ можно представить
в виде:
\begin{equation}
    Z
    = \sum_{k=1}^Y X_k .
\end{equation}

Математическое ожидание $Z$ вычислим с помощью условного математического ожидания $Z$ относительно $Y$:
\begin{equation}
    \expectation{Z}
    = \expectation{\expectation{\condition{Z}{Y}}}.
\end{equation}

Определим значение условного математического ожидания $\expectation{\condition{Z}{Y}}$ при различных значениях $Y$. Пусть $Y = m$, тогда:
\begin{gather}
    Z = \sum_{k=1}^m X_k, \\
    %
    \expectation{\condition{Z}{Y=m}}
    = \expectation{\sum_{k=1}^m X_k}
    = \sum_{k=1}^m \expectation{X_k}
    = m \cdot \expectation{X_1} .
\end{gather}
Поскольку равенство справедливо при любых $m$, то условное математическое ожидание можно представить в виде:
\begin{equation}
    \label{10:463:conditional_expectation}
    \expectation{\condition{Z}{Y}} = Y \cdot \expectation{X_1} ,
\end{equation}
откуда
\begin{equation}
    \expectation{Z}
    = \expectation{\condition{Z}{Y}}
    = \expectation{Y \cdot \expectation{X_1}}
    = \expectation{Y} \cdot \expectation{X_1}
\end{equation}
Величины $X$ и $X_1$ --- количество очков, выпадающих при одном броске, поэтому у них одинаковое математическое ожидание:
\begin{gather}
    \expectation{Y}
    = 1 \cdot \frac{1}{6} + 2 \cdot \frac{1}{6} + 3 \cdot \frac{1}{6} + 4 \cdot \frac{1}{6} + 5 \cdot \frac{1}{6} + 6 \cdot \frac{1}{6}
    = \frac{21}{6}
    = \frac{7}{2}, \\
    \expectation{X_1} = \expectation{Y}.
\end{gather}
Таким образом,
\begin{equation}
    \expectation{Z}
    = \frac{7}{2} \cdot \frac{7}{2}
    = \frac{49}{4} .
\end{equation}

При вычислении дисперсии воспользуемся равенством:
\begin{equation}
    \variance{Z}
    = \expectation{Z^2} - \expectation{Z}^2 ,
\end{equation}
где второй начальный момент вычислим с помощью условного математического ожидания:
\begin{equation}
    \expectation{Z^2}
    = \expectation{\expectation{\condition{Z^2}{Y}}} ,
\end{equation}
Пусть $Y = m$:
\begin{multline}
    \expectation{\condition{Z^2}{Y=m}}
    = \expectation{\left ( \sum_{k=1}^m X_k \right )^2}
    = \expectation{\sum_{k=1}^m X_k^2 + \sum_{k=1}^m \sum_{j=1, j \neq k}^m X_k X_j} = \\
    %
    = \sum_{k=1}^m \expectation{X_k^2} + \sum_{k=1}^m \sum_{j=1, j \neq k}^m \expectation{X_k X_j}
    = m \cdot \expectation{X_1^2} + m(m-1) \cdot \expectation{X_1 X_2} = \\
    %
    = m \cdot \expectation{X_1^2} + m(m-1) \cdot \expectation{X_1} \expectation{X_2}
    = m \cdot \expectation{X_1^2} + m(m-1) \cdot \expectation{X_1}^2 = \\
    %
    = m \cdot \expectation{X_1^2} + m^2 \cdot \expectation{X_1}^2 - m \cdot \expectation{X_1}^2
    = m \cdot \left ( \expectation{X_1^2} - \expectation{X_1}^2 \right ) + m^2 \cdot \expectation{X_1}^2 = \\
    %
    = m \cdot \variance{X_1} + m^2 \cdot \expectation{X_1}^2 .
\end{multline}
Таким образом,
\begin{gather}
    \expectation{\condition{Z^2}{Y}}
    = Y \cdot \variance{X_1} + Y^2 \cdot \expectation{X_1}^2 , \\
    %
    \expectation{\expectation{\condition{Z^2}{Y}}}
    = \expectation{Y \cdot \variance{X_1} + Y^2 \cdot \expectation{X_1}^2}
    = \expectation{Y} \cdot \variance{X_1} + \expectation{Y^2} \cdot \expectation{X_1}^2,
\end{gather}
и дисперсия:
\begin{multline}
    \variance{Z}
    = \expectation{Y} \cdot \variance{X_1} + \expectation{Y^2} \cdot \expectation{X_1}^2 - \expectation{Y}^2 \cdot \expectation{X_1}^2 = \\
    %
    = \expectation{Y} \cdot \variance{X_1} + \left ( \expectation{Y^2} - \expectation{Y}^2 \right ) \cdot \expectation{X_1}^2
    = \expectation{Y} \cdot \variance{X_1} + \variance{Y} \cdot \expectation{X_1}^2.
\end{multline}
Причем величины $Y$ и $X_1$ имеют одинаковое распределение и
\begin{multline}
    \expectation{Y^2}
    = 1^2 \cdot \frac{1}{6} + 2^2 \cdot \frac{1}{6} + 3^2 \cdot \frac{1}{6} + 4^2 \cdot \frac{1}{6} + 5^2 \cdot \frac{1}{6} + 6^2 \cdot \frac{1}{6} = \\
    %
    = \frac{1 + 4 + 9 + 16 + 25 + 36}{6}
    = \frac{91}{6},
\end{multline}
а дисперсия:
\begin{equation}
    \variance{Y}
    = \expectation{Y^2} - \expectation{Y}^2
    = \frac{91}{6} - \frac{49}{4}
    = \frac{91 \cdot 2 - 49 \cdot 3}{12}
    = \frac{182 - 147}{12}
    = \frac{35}{12},
\end{equation}
тогда
\begin{multline}
    \variance{Z}
    = \frac{7}{2} \cdot \frac{35}{12} + \frac{35}{12} \cdot \left ( \frac{7}{2} \right )^2
    = \frac{7}{2} \cdot \frac{35}{12} \cdot \left ( 1 + \frac{7}{2} \right )
    = \frac{7}{2} \cdot \frac{35}{12} \cdot \frac{9}{2} = \\
    %
    = \frac{7}{2} \cdot \frac{35}{4} \cdot \frac{3}{2}
    = \frac{245 \cdot 3}{16}
    = \frac{735}{16}.
\end{multline}

\subsection*{Ответ:}
$\expectation{Z} = \frac{49}{4}$, $\variance{Z} = \frac{735}{16}$.

\section*{Задача 18.515}

Случайные величины $X$ и $Y$ независимы и подчиняются одному и тому же индикаторному распределению $B(1,p)$. Описать законы распределения случайных величин
$Z = X + Y$ и $V = X Y$.
\subsection*{Решение:}
Величина $X$ подчиняется индикаторному распределению $B(1,p)$ означает, что $X$ принимает значение 1 с веростноятью $p$ и 0 с вероятностью $1-p$:

\begin{tabular}{|c|c|}
    \hline
    $X$ & $P$   \\
    \hline
    0   & $1-p$ \\
    \hline
    1   & $p$   \\
    \hline
\end{tabular}

Составим таблицы значения для вероятностей и значений величин $Z$ и $V$:

\begin{tabular}{|c|c|c|c|c|}
    \hline
    $X$ & $Y$ & $P$                 & $Z$ & $V$ \\
    \hline
    0   & 0   & $(1-p) \cdot (1-p)$ & 0   & 0   \\
    \hline
    1   & 0   & $p \cdot (1-p)$     & 1   & 0   \\
    \hline
    0   & 1   & $(1-p) \cdot p$     & 1   & 0   \\
    \hline
    1   & 1   & $p \cdot p$         & 2   & 1   \\
    \hline
\end{tabular}

Собираем различные значения величины $Z$, при одинаковых значениях суммируем вероятности:

\begin{tabular}{|c|c|}
    \hline
    $Z$ & $P$                             \\
    \hline
    0   & $(1-p) \cdot (1-p)$             \\
    \hline
    1   & $p \cdot (1-p) + (1-p) \cdot p$ \\
    \hline
    2   & $p \cdot p$                     \\
    \hline
\end{tabular}

Аналогично для величины $V$:

\begin{tabular}{|c|c|}
    \hline
    $V$ & $P$                                                 \\
    \hline
    0   & $(1-p) \cdot (1-p) + p \cdot (1-p) + (1-p) \cdot p$ \\
    \hline
    1   & $p \cdot p$                                         \\
    \hline
\end{tabular}

\subsection*{Ответ:}
Закон распределения $Z$:

\begin{tabular}{|c|c|}
    \hline
    $Z$ & $P$         \\
    \hline
    0   & $(1-p)^2$   \\
    \hline
    1   & $2 p (1-p)$ \\
    \hline
    2   & $p^2$       \\
    \hline
\end{tabular}

Закон распределения величины $V$:

\begin{tabular}{|c|c|}
    \hline
    $V$ & $P$                   \\
    \hline
    0   & $(1-p)^2 + 2 p (1-p)$ \\
    \hline
    1   & $p^2$                 \\
    \hline
\end{tabular}

\section*{Задача 18.518}

Случайный вектор $\left ( X, Y \right )$ распределен по закону, определяемому плотностью распределения вероятностей
$$
f_{X, Y} ( x, y )
= \left \{
\begin{array}{ll}
    x + y, & 0 \le x \le 1, 0 \le y \le 1 \\
    0,     & \text{в остальных случаях}
\end{array}
\right .
$$
Найти плотности распределения вероятностей функций:
\begin{enumerate}
    \item $Z = X + Y$,
    \item $U = XY$.
\end{enumerate}

\subsection*{Решение:}
\begin{enumerate}
    \item Плотность вероятности $f_Z(z)$ величины $Z$ находим интегрированием совместной плотности $f_{X,Y}(x,y)$ с учётом условия $x+y=z$:
    \begin{equation}
        f_Z(z)
        = \int \limits_{-\infty}^{\infty} f_{X,Y}(x, z-x) dx
        = \left \{
        \begin{array}{ll}
            0,                                      & z < 0       \\
            \int \limits_0^z f_{X,Y}(x,z-x) dx,     & 0 < z \le 1 \\
            \int \limits_{z-1}^1 f_{X,Y}(x,z-x) dx, & 1 < z \le 2 \\
            0,                                      & 2 < z
        \end{array}
        \right .
    \end{equation}

    \begin{figure}[!h]
        \center
        \begin{tikzpicture}[scale=5]
            % оси
            \draw [->] ( -0.5, 0 ) -- ( 1.5, 0 ) node [below] at ( 1.5, 0 ) {$x$};
            \draw [->] ( 0, -0.5 ) -- ( 0, 1.5 ) node [left] at ( 0, 1.5 ) {$y$};

            % квадратик
            \draw [fill=gray!20] ( 0, 0 ) rectangle ( 1, 1 );
            \node [below] at ( 1, 0 ) {$1$};
            \node [left] at ( 0, 1 ) {$1$};

            % прямые
            \draw [dashed] ( -0.5, 0.3 ) -- ( 0.3, -0.5 ) node [below] at ( 0.3, -0.5 ) {$x + y = -0.2$};
            \draw [dashed] ( -0.5, 0.8 ) -- ( 0.8, -0.5 ) node [below] at ( 0.8, -0.5 ) {$x + y = 0.3$};
            \draw [dashed] ( -0.3, 1.5 ) -- ( 1.5, -0.3 ) node [below] at ( 1.5, -0.3 ) {$x + y = 1.2$};
            \draw [dashed] ( 0.6, 1.5 ) -- ( 1.5, 0.6 ) node [below] at ( 1.5, 0.6 ) {$x + y = 2.1$};

            % отрезки
            \draw [ultra thick] ( 0, 0.3 ) -- ( 0.3, 0 );
            \draw [ultra thick] ( 0.2, 1 ) -- ( 1, 0.2 );
        \end{tikzpicture}
        \caption{Вычисление $f_Z(z)$: отрезки с ненулевыми значениями плотности.}
    \end{figure}

    Интеграл для второго случая ($0 < z \le 1$):
    \begin{equation}
        \int \limits_0^z f_{X,Y}(x,z-x) dx
        = \int \limits_0^z \left ( x + z - x \right ) dx
        = \int \limits_0^z z dx
        = \left . z x \right |_0^z
        = z^2
    \end{equation}

    Интеграл для третьего случая ($1 < z \le 2$):
    \begin{equation}
        \int \limits_{z-1}^1 f_{X,Y}(x,z-x) dx
        = \int \limits_{z-1}^1 \left ( x + z - x \right ) dx
        = \int \limits_{z-1}^1 z dx
        = \left . z x \right |_{z-1}^1
        = z - z (z - 1)
        = 2 z - z^2
    \end{equation}

    Таким образом,
    \begin{equation}
        f_Z(z)
        = \left \{
        \begin{array}{ll}
            0,        & z < 0       \\
            z^2,      & 0 < z \le 1 \\
            2z - z^2, & 1 < z \le 2 \\
            0,        & 2 < z
        \end{array}
        \right .
    \end{equation}

    \item Для величины $U$ сперва найдем функцию распределения:
    \begin{equation}
        F_U(u)
        = \probability{XY < u}
        = \left \{
        \begin{array}{ll}
            0,                                          & u < 0         \\
            \iint \limits_{xy < u} f_{X,Y}(x, y) dy dx, & 0 \le u \le 1 \\
            1,                                          & 1 < u
        \end{array}
        \right .
    \end{equation}

    Вычислим интеграл для второго случая ($0 \le u \le 1$):
    \begin{multline}
        \iint \limits_{xy < u} f_{X,Y}(x, y) dy dx
        = \int \limits_0^u \int \limits_0^1 ( x + y ) dy dx + \int \limits_u^1 \int \limits_0^{\frac{u}{x}} ( x + y ) dy dx = \\
        %
        = \int \limits_0^u \left . \left ( x y + \frac{y^2}{2} \right ) \right |_0^1 dx + \int \limits_u^1 \left . \left ( x y + \frac{y^2}{2} \right ) \right |_0^{\frac{u}{x}} dx = \\
        = \int \limits_0^u \left ( x + \frac{1}{2} \right ) dx + \int \limits_u^1 \left ( x \frac{u}{x} + \frac{u^2}{2x^2} \right ) dx = \\
        = \left . \left ( \frac{x^2}{2} + \frac{1}{2} x \right ) \right |_0^u + \left . \left ( u x + \frac{u^2}{2} \left ( - \frac{1}{x} \right ) \right ) \right |_u^1 dx = \\
        %
        = \frac{u^2}{2} + \frac{1}{2} u + u - \frac{u^2}{2} - u^2 - \frac{u^2}{2} \left ( - \frac{1}{u} \right )
        = \frac{1}{2} u + u - u^2 + \frac{u}{2}
        = 2 u - u^2
    \end{multline}

    \begin{figure}[!h]
        \center
        \begin{tikzpicture}[scale=5]
            % область 1
            \draw [fill=gray!20] ( 0, 0 ) rectangle ( 0.2, 1 );
            % область 2
            \draw [fill=gray!20] ( 0.2, 0 ) -- ( 0.2, 1 ) to [out=-83,in=175] ( 1, 0.2 ) -- ( 1, 0 );

            % оси
            \draw [->] ( -0.1, 0 ) -- ( 1.1, 0 ) node [below] at ( 1.1, 0 ) {$x$};
            \draw [->] ( 0, -0.1 ) -- ( 0, 1.1 ) node [left] at ( 0, 1.1 ) {$y$};

            % квадратик
            \node [below] at ( 1, 0 ) {$1$};
            \node [left] at ( 0, 1 ) {$1$};

            % гипербола
            \draw [ultra thick, domain=0.2:1] plot (\x, {0.2/\x});

            % пунктир
            \draw [dashed] ( 0.2, 0 ) -- ( 0.2, 1 ) node [below] at ( 0.2, 0 ) {$u$};

            % площади
            \node at ( 0.1, 0.5 ) {$1$};
            \node at ( 0.6, 0.2 ) {$2$};
        \end{tikzpicture}
        \caption{Вычисление $F_U(u)$: 1 - область первого интеграла, 2 - область второго интеграла.}
    \end{figure}

    Таким образом, функция распределения имеет вид:
    \begin{equation}
        F_U(u)
        = \left \{
        \begin{array}{ll}
            0,         & u < 0         \\
            2 u - u^2, & 0 \le u \le 1 \\
            1,         & 1 < u
        \end{array}
        \right .
    \end{equation}

    Откуда плотность вероятности $f_U(u)$ величины $U$:
    \begin{equation}
        f_U(u)
        = \derivative{u} F_U(u)
        = \left \{
        \begin{array}{ll}
            0,      & u < 0         \\
            2 - 2u, & 0 \le u \le 1 \\
            1,      & 1 < u
        \end{array}
        \right .
    \end{equation}

%        \item Плотность вероятности $f_U(u)$ величины $U$ найдем аналогичным образом:
%        \begin{equation}
%            f_U(u)
%            = \int \limits_{-\infty}^{\infty} f_{X,Y} \left ( x, \frac{u}{x} \right ) dx
%            = \left \{
%            \begin{array}{ll}
%                0,                                                              & u \le 0     \\
%                \int \limits_{u}^{1} f_{X,Y} \left ( x, \frac{u}{x} \right ) dx & 0 < u \le 1 \\
%                0,                                                              & 1 < u
%            \end{array}
%            \right .
%        \end{equation}
%
%        Интеграл во втором случае ($0 \le u \le 1$):
%        \begin{multline}
%            \int \limits_{u}^{1} f_{X,Y} \left ( x, \frac{u}{x} \right ) dx
%            = \int \limits_{u}^{1} \left ( x + \frac{u}{x} \right ) dx
%            = \left . \left ( \frac{x^2}{2} + u \ln x \right ) \right |_u^1 = \\
%            %
%            = \frac{1}{2} + u \ln 1 - \frac{u^2}{2} - u \ln u
%            = \frac{1}{2} - \frac{u^2}{2} - u \ln u
%        \end{multline}
\end{enumerate}

\subsection*{Ответ:}
\begin{enumerate}
    \item Плотность вероятности величины $Z$:
    $$
    f_Z(z)
    = \left \{
    \begin{array}{ll}
        0,        & z < 0       \\
        z^2,      & 0 < z \le 1 \\
        2z - z^2, & 1 < z \le 2 \\
        0,        & 2 < z
    \end{array}
    \right .
    .
    $$

    \item Плотность вероятности величины $U$:
    $$
    f_U(u)
    = \derivative{u} F_U(u)
    = \left \{
    \begin{array}{ll}
        0,      & u < 0         \\
        2 - 2u, & 0 \le u \le 1 \\
        1,      & 1 < u
    \end{array}
    \right .
    .
    $$
\end{enumerate}

\section*{Задача 18.521}

Случайные величины $X$ и $Y$ независимы и одинаково распределены по закону $\mathcal{N}(0, \sigma^2)$. Установить, по какому закону распределена случайная величина
$R = \sqrt{X^2 + Y^2}$.
\subsection*{Решение:}
Пусть $F_R(r)$ --- функция распределения величины $R$:
\begin{multline}
    F_R(r)
    = \probability{R < r}
    = \probability{\sqrt{X^2 + Y^2} < r}
    = \probability{X^2 + Y^2 < r^2} = \\
    %
    = \left \{
    \begin{array}{ll}
        0,                                                   & r \le 0 \\
        \iint \limits_{x^2 + y^2 < r^2} f_{X,Y}(x, y) dy dx, & 0 < r   \\
    \end{array}
    \right .
\end{multline}
где $f_{X,Y}(x, y)$ --- совместная плотность вероятности вектора $\left ( X, Y \right )$, равная произведению плотности вероятности $f_X(x)$ величины $X$ и
плотности вероятности $f_Y(y)$ величины $Y$ поскольку величины $X$ и $Y$ \textbf{независимы}:
\begin{equation}
    f_{X,Y}(x, y) = f_X(x) \cdot f_Y(y),
\end{equation}
Одномерные плотности имеют одинаковый вид:
\begin{gather}
    f_X(x) = \frac{1}{\sqrt{2 \pi} \sigma} e^{- \frac{x^2}{2 \sigma^2}} , \\
    f_Y(y) = \frac{1}{\sqrt{2 \pi} \sigma} e^{- \frac{y^2}{2 \sigma^2}} .
\end{gather}

Вычислим итеграл в функции распределения (случай $0 < r$):
\begin{equation}
    \iint \limits_{x^2 + y^2 < r^2} f_{X,Y}(x, y) dy dx
    = \iint \limits_{x^2 + y^2 < r^2} \frac{1}{\sqrt{2 \pi} \sigma} e^{- \frac{x^2}{2 \sigma^2}} \cdot \frac{1}{\sqrt{2 \pi} \sigma} e^{- \frac{y^2}{2 \sigma^2}} dy dx
    = \iint \limits_{x^2 + y^2 < r^2} \frac{1}{2 \pi \sigma^2} e^{- \frac{x^2 + y^2}{2 \sigma^2}} dy dx
\end{equation}
Для вычисления итеграла перейдем к полярным координатам
\begin{gather}
    x = \rho \cos \varphi , \\
    y = \rho \sin \varphi .
\end{gather}
Якобиан преобразования:
\begin{equation}
    J
    = \begin{vmatrix}
          \cos \varphi & - \rho \sin \varphi \\
          \sin \varphi & \rho \cos \varphi   \\
    \end{vmatrix}
    = \rho \cos^2 \varphi + \rho \sin^2 \varphi = \rho
    .
\end{equation}

В результате замены интеграл принимает вид
\begin{multline}
    \iint \limits_{x^2 + y^2 < r^2} f_{X,Y}(x, y) dy dx
    = \iint \limits_{\rho^2 < r^2, 0 \le \varphi \le 2 \pi} \frac{1}{2 \pi \sigma^2} e^{- \frac{\rho^2}{2 \sigma^2}} \rho d \varphi d \rho
    = \int \limits_0^{r} \int \limits_0^{2 \pi} \frac{1}{2 \pi \sigma^2} e^{- \frac{\rho^2}{2 \sigma^2}} \rho d \varphi d \rho = \\
    %
    = \int \limits_0^{r} 2 \pi \frac{1}{2 \pi \sigma^2} e^{- \frac{\rho^2}{2 \sigma^2}} \rho d \rho
    = \int \limits_0^{r} \frac{\rho}{\sigma^2} e^{- \frac{\rho^2}{2 \sigma^2}} d \rho
    = \left . \left ( - e^{- \frac{\rho^2}{2 \sigma^2}} \right ) \right |_0^{r}
    = 1 - e^{-\frac{r^2}{2 \sigma^2}}
\end{multline}

Таким образом, функция распределения величины $R$:
\begin{equation}
    F_R(r)
    = \left \{
    \begin{array}{ll}
        0,                               & r \le 0 \\
        1 - e^{-\frac{r^2}{2 \sigma^2}}, & 0 < r   \\
    \end{array}
    \right .
\end{equation}
и плотность вероятности величины $R$:
\begin{equation}
    f_R(r)
    = \derivative{r} F_R(r)
    = \left \{
    \begin{array}{ll}
        0,                                                                       & r \le 0 \\
        - e^{-\frac{r^2}{2 \sigma^2}} \left ( - \frac{2 r}{2 \sigma^2} \right ), & 0 < r   \\
    \end{array}
    \right .
    = \left \{
    \begin{array}{ll}
        0,                                              & r \le 0 \\
        \frac{r}{\sigma^2} e^{-\frac{r^2}{2 \sigma^2}}, & 0 < r   \\
    \end{array}
    \right .
\end{equation}
\subsection*{Ответ:}
Закон распределения Релея. Функция плотности вероятности $f(r)$:
$$
f(r)
= \left \{
\begin{array}{ll}
    0,                                              & r \le 0 \\
    \frac{r}{\sigma^2} e^{-\frac{r^2}{2 \sigma^2}}, & 0 < r   \\
\end{array}
\right .
$$

\section*{Задачи 18.525, 18.526}

Случайные величины $X$ и $Y$ независимы и одинаково распределены с функцией распределения $F(x)$. Найти функции распределения случайных величин $U = \min \left \{ X, Y \right \}$
и $V = \max \left \{ X, Y \right \}$, а также совместную функцию распределения $F_{U,V}(u,v)$.

\subsection*{Решение:}

Пусть $F_U(u)$ --- функция распределения случайной величины $U$, тогда:
\begin{multline}
    F_U(u)
    = \probability{U < u} = \\
    %
    = \probability{\min \left \{ X, Y \right \} < u}
    = 1 - \probability{\min \left \{ X, Y \right \} \ge u}
    = 1 - \probability{X \ge u, Y \ge u} = \\
    %
    = 1 - \probability{X \ge u} \cdot \probability{Y \ge u}
    = 1 - \left ( 1 - \probability{X < u} \right ) \cdot \left ( 1 - \probability{Y < u} \right ) = \\
    %
    = 1 - \left ( 1 - F(u) \right ) \cdot \left ( 1 - F(u) \right )
    = 1 - \left ( 1 - F(u) \right )^2.
\end{multline}

Пусть $F_V(v)$ --- функция распределения случайной величины $V$, тогда:
\begin{multline*}
    F_V(v)
    = \probability{V < v}
    = \probability{\max \left \{ X, Y \right \} < v}
    = \probability{X < v, Y < v} = \\
    %
    = \probability{X < v} \cdot \probability{Y < v}
    = F(v) \cdot F(v)
    = F(v)^2 .
\end{multline*}

Совместная функция распределения:
\begin{equation}
    F_{U,V}(u,v)
    = \probability{U < u, V < v} .
\end{equation}
Заметим, что в случае $v \le u$:
\begin{gather}
    \event{\max \left \{ X, Y \right \} < v} \subseteq \event{\min \left \{ X, Y \right \} < u} , \\
    \event{V < v} \subseteq \event{U < u} ,
\end{gather}
поэтому
\begin{equation}
    \probability{U < u, V < v}
    = \probability{V < v}
    = F_V(v)
    = F(v)^2.
\end{equation}
В случае $u < v$ рассмотрим разложение:
\begin{gather}
    \event{U < v, V < v} = \event{U < u, V < v} \cup \event{u \le U < v, V < v} , \\
    \probability{U < v, V < v} = \probability{U < u, V < v} + \probability{u \le U < v, V < v} ,
\end{gather}
где вероятность в левой части
\begin{multline}
    \probability{U < v, V < v}
    = \probability{\min \left \{ X, Y \right \} < v, \max \left \{ X, Y \right \} < v} = \\
    %
    = \probability{\max \left \{ X, Y \right \} < v}
    = F_V(v)
    = F(v)^2,
\end{multline}
и вторая вероятность в правой части
\begin{multline}
    \probability{u \le U < v, V < v}
    = \probability{u \le \min \left \{ X, Y \right \} < v, \max \left \{ X, Y \right \} < v} = \\
    %
    = \probability{u \le X < v, u \le Y < v}
    = \probability{u \le X < v} \cdot \probability{u \le Y < v} = \\
    %
    = \left ( F(v) - F(u) \right ) \cdot \left ( F(v) - F(u) \right )
    = \left ( F(v) - F(u) \right )^2 .
\end{multline}
Таким образом,
\begin{gather}
    F(v)^2 = \probability{U < u, V < v} + \left ( F(v) - F(u) \right )^2 , \\
    \probability{U < u, V < v} = F(v)^2 - \left ( F(v) - F(u) \right )^2 ,
\end{gather}
и совместная функция распределения:
\begin{equation}
    F_{U,V}(u,v)
    = \left \{
    \begin{array}{ll}
        F(v)^2,                                  & v \le u \\
        F(v)^2 - \left ( F(v) - F(u) \right )^2, & u < v
    \end{array}
    \right .
    .
\end{equation}

\subsection*{Ответ:}
\begin{enumerate}
    \item $F_U(u) = 1 - \left ( 1 - F(u) \right )^2$,
    \item $F_V(v) = F(v)^2$,
    \item $F_{U,V}(u,v)
    = \left \{
    \begin{array}{ll}
        F(v)^2,                                  & v \le u \\
        F(v)^2 - \left ( F(v) - F(u) \right )^2, & u < v
    \end{array}
    \right .
    .
    $
\end{enumerate}

\section*{Задача 18.530}

Доказать композиционную устойчивость закона Пуассона и найти $\expectation{Z}$ и $\variance{Z}$, где $Z = X + Y$, $X$ и $Y$ --- независимые пуассоновские случайные величины с
параметрами соответственно $\lambda_1$ и $\lambda_2$.

\subsection*{Решение:}

Вычислим вероятности событий $\event{Z = m}$:
\begin{multline}
    \probability{Z = m}
    = \probability{X + Y = m}
    = \probability{\bigcup_{k=0}^m \event{X = k, Y = m - k}} = \\
    %
    = \sum_{k=0}^m \probability{X = k, Y = m - k}
    = \sum_{k=0}^m \probability{X = k} \cdot \probability{Y = m - k} = \\
    %
    = \sum_{k=0}^m \frac{\lambda_1^k}{k!} e^{-\lambda_1} \cdot \frac{\lambda_2^{m-k}}{(m-k)!} e^{-\lambda_2}
    = e^{-\lambda_1} e^{-\lambda_2} \sum_{k=0}^m \frac{\lambda_1^k}{k!} \frac{\lambda_2^{m-k}}{(m-k)!} = \\
    %
    = e^{-(\lambda_1+\lambda_2)} \sum_{k=0}^m \frac{1}{k!(m-k)!} \lambda_1^k \lambda_2^{m-k}
    = e^{-(\lambda_1+\lambda_2)} \sum_{k=0}^m \frac{1}{m!} \frac{m!}{k!(m-k)!} \lambda_1^k \lambda_2^{m-k} = \\
    %
    = e^{-(\lambda_1+\lambda_2)} \frac{1}{m!} \sum_{k=0}^m \frac{m!}{k!(m-k)!} \lambda_1^k \lambda_2^{m-k}
    = e^{-(\lambda_1+\lambda_2)} \frac{1}{m!} \sum_{k=0}^m C_m^k \lambda_1^k \lambda_2^{m-k} = \\
    = e^{-(\lambda_1+\lambda_2)} \frac{1}{m!} (\lambda_1 + \lambda_2)^m
    = \frac{(\lambda_1 + \lambda_2)^m}{m!} e^{-(\lambda_1+\lambda_2)}.
\end{multline}
Таким образом, $Z = X + Y \sim P( \lambda_1 + \lambda_2 )$.

В силу линейности математического ожидания:
\begin{equation}
    \expectation{Z}
    = \expectation{X + Y}
    = \expectation{X} + \expectation{Y}
    = \lambda_1 + \lambda_2 .
\end{equation}
и в силу независимости величин $X$ и $Y$:
\begin{equation}
    \variance{Z}
    = \variance{X + Y}
    = \variance{X} + \variance{Y} + 2 \covariance{X}{Y}
    = \variance{X} + \variance{Y}
    = \lambda_1 + \lambda_2 .
\end{equation}

Первый и второй начальные моменты случайных величин, имеющих распределение Пуассона, можно вычислить следующим образом. Обозначим для краткости $\lambda = \lambda_1 + \lambda_2$,
тогда математическое ожидание $Z$:
\begin{multline}
    \expectation{Z}
    = \sum_{k=0}^{\infty} k \frac{\lambda^k}{k!} e^{-\lambda}
    = \sum_{k=1}^{\infty} k \frac{\lambda^k}{k!} e^{-\lambda}
    = e^{-\lambda} \lambda \sum_{k=1}^{\infty} \frac{k \lambda^{k-1}}{k!}
    = e^{-\lambda} \lambda \sum_{k=1}^{\infty} \left ( \frac{\lambda^k}{k!} \right )_{\lambda}^{\prime} = \\
    %
    = e^{-\lambda} \lambda \left ( \sum_{k=1}^{\infty} \frac{\lambda^k}{k!} \right )_{\lambda}^{\prime}
    = e^{-\lambda} \lambda \left ( 1 + \sum_{k=1}^{\infty} \frac{\lambda^k}{k!} - 1 \right )_{\lambda}^{\prime} = \\
    = e^{-\lambda} \lambda \left ( \sum_{k=0}^{\infty} \frac{\lambda^k}{k!} - 1 \right )_{\lambda}^{\prime}
    = e^{-\lambda} \lambda \left ( e^\lambda - 1 \right )_{\lambda}^{\prime}
    = e^{-\lambda} \lambda e^\lambda
    = \lambda .
\end{multline}

Второй начальный момент можно вычислить аналогично:
\begin{multline}
    \expectation{Z^2}
    = \sum_{k=0}^{\infty} k^2 \frac{\lambda^k}{k!} e^{-\lambda}
    = \sum_{k=1}^{\infty} k^2 \frac{\lambda^k}{k!} e^{-\lambda}
    = e^{-\lambda} \lambda \sum_{k=1}^{\infty} k \frac{k \lambda^{k-1}}{k!}
    = e^{-\lambda} \lambda \sum_{k=1}^{\infty} \left ( k \frac{\lambda^k}{k!} \right )_{\lambda}^{\prime} = \\
    %
    = e^{-\lambda} \lambda \left ( \sum_{k=1}^{\infty} k \frac{\lambda^k}{k!} \right )_{\lambda}^{\prime}
    = e^{-\lambda} \lambda \left ( \lambda \sum_{k=1}^{\infty} \frac{k \lambda^{k-1}}{k!} \right )_{\lambda}^{\prime}
    = e^{-\lambda} \lambda \left ( \lambda \sum_{k=1}^{\infty} \left ( \frac{\lambda^{k}}{k!} \right )_{\lambda}^{\prime} \right )_{\lambda}^{\prime} = \\
    %
    = e^{-\lambda} \lambda \left ( \lambda \left ( \sum_{k=1}^{\infty} \frac{\lambda^{k}}{k!} \right )_{\lambda}^{\prime} \right )_{\lambda}^{\prime}
    = e^{-\lambda} \lambda \left ( \lambda \left ( e^\lambda - 1 \right )_{\lambda}^{\prime} \right )_{\lambda}^{\prime}
    = e^{-\lambda} \lambda \left ( \lambda e^\lambda \right )_{\lambda}^{\prime} = \\
    %
    = e^{-\lambda} \lambda \left ( e^\lambda + \lambda e^\lambda \right )
    = \lambda + \lambda^2.
\end{multline}
Откуда дисперсия
\begin{equation}
    \variance{Z}
    = \expectation{Z^2} - \expectation{Z}^2
    = \lambda + \lambda^2 - \lambda^2
    = \lambda.
\end{equation}

\subsection*{Ответ:}
$\expectation{Z} = \lambda_1 + \lambda_2$, $\variance{Z} = \lambda_1 + \lambda_2$.

\section*{Задача 18.532}

Доказать композиционную устойчивость нормального закона $\mathcal{N} \left ( m, \sigma^2 \right )$.

\subsection*{Решение:}

Пусть $X$ и $Y$ --- независимые случайные величины, имеющие распределения $X \sim \mathcal{N} \left ( m_X, \sigma_X^2 \right )$ и
$Y \sim \mathcal{N} \left ( m_Y, \sigma_Y^2 \right )$. Функция распределения $F_Z(z)$ случайной величины $Z = X + Y$:
\begin{multline}
    F_Z(z)
    = \probability{Z < z}
    = \probability{X + Y < z} = \\
    %
    = \iint \limits_{X + Y < z} f_{X,Y}(x,y) dy dx
    = \int \limits_{-\infty}^\infty \int \limits_{-\infty}^{z-x} f_{X,Y}(x,y) dy dx,
\end{multline}
где $f_{X,Y}(x,y)$ --- функция плотности вероятности, имеющая вид:
\begin{multline}
    f_{X,Y}(x,y)
    = \frac{1}{\sqrt{2 \pi} \sigma_X} e^{- \frac{1}{2} \frac{(x - m_X)^2}{\sigma_X^2}} \cdot \frac{1}{\sqrt{2 \pi} \sigma_Y} e^{- \frac{1}{2} \frac{(y - m_Y)^2}{\sigma_Y^2}} = \\
    %
    = \frac{1}{2 \pi \sigma_X \sigma_Y} e^{- \frac{1}{2} \left ( \frac{(x - m_X)^2}{\sigma_X^2} + \frac{(y - m_Y)^2}{\sigma_Y^2} \right )} .
\end{multline}
Таким образом, получим интеграл вида:
\begin{equation}
    F_Z(z)
    = \frac{1}{2 \pi \sigma_X \sigma_Y} \int \limits_{-\infty}^\infty \int \limits_{-\infty}^{z-x} e^{- \frac{1}{2} \left ( \frac{(x - m_X)^2}{\sigma_X^2} + \frac{(y - m_Y)^2}{\sigma_Y^2} \right )} dy dx .
\end{equation}
Данный интеграл не выражается через элементарные функции.

Плотность вероятности $f_Z(z)$ случайной величины $Z$:
\begin{multline}
    f_Z(z)
    = \derivative{z} F_Z(z)
    = \derivative{z} \frac{1}{2 \pi \sigma_X \sigma_Y} \int \limits_{-\infty}^\infty \int \limits_{-\infty}^{z-x} e^{- \frac{1}{2} \left ( \frac{(x - m_X)^2}{\sigma_X^2} + \frac{(y - m_Y)^2}{\sigma_Y^2} \right )} dy dx = \\
    %
    = \frac{1}{2 \pi \sigma_X \sigma_Y} \int \limits_{-\infty}^\infty e^{- \frac{1}{2} \left ( \frac{(x - m_X)^2}{\sigma_X^2} + \frac{(z - x - m_Y)^2}{\sigma_Y^2} \right )} dx .
\end{multline}
Преобразовывая выражение в показателе, получим:
\begin{multline}
    \frac{(x - m_X)^2}{\sigma_X^2} + \frac{(z - x - m_Y)^2}{\sigma_Y^2}
    = \frac{\sigma_Y^2 ( x - m_X )^2 + \sigma_X^2 (z - x - m_Y)^2}{\sigma_X^2 \sigma_Y^2} = \\
    %
    = \frac{\sigma_Y^2 x^2 - 2 x \sigma_Y^2 m_X + \sigma_Y^2 m_X^2 + \sigma_X^2 x^2 - 2 x \sigma_X^2 (z - m_Y) + \sigma_X^2 (z - m_Y)^2}{\sigma_X^2 \sigma_Y^2} = \\
    %
    = \frac{(\sigma_Y^2 + \sigma_X^2) x^2 - 2 x ( \sigma_Y^2 m_X + \sigma_X^2 (z - m_Y) ) + \sigma_Y^2 m_X^2 + \sigma_X^2 (z - m_Y)^2}{\sigma_X^2 \sigma_Y^2} = \\
    %
    = \frac{x^2 - 2 x \frac{\sigma_Y^2 m_X + \sigma_X^2 (z - m_Y)}{(\sigma_Y^2 + \sigma_X^2)} + \frac{\sigma_Y^2 m_X^2 + \sigma_X^2 (z - m_Y)^2}{(\sigma_Y^2 + \sigma_X^2)}}{\frac{\sigma_X^2 \sigma_Y^2}{\sigma_X^2 + \sigma_Y^2}} = \\
    %
    = \frac{x^2 - 2 x A + B}{\frac{\sigma_X^2 \sigma_Y^2}{\sigma_X^2 + \sigma_Y^2}}
    = \frac{\left ( x - A \right )^2 - A^2 + B}{\frac{\sigma_X^2 \sigma_Y^2}{\sigma_X^2 + \sigma_Y^2}} .
\end{multline}
Таким образом,
\begin{multline}
    f_Z(z)
    = \frac{1}{2 \pi \sigma_X \sigma_Y} \int \limits_{-\infty}^\infty e^{ -\frac{1}{2} \frac{\left ( x - A \right )^2 - A^2 + B}{\frac{\sigma_X^2 \sigma_Y^2}{\sigma_X^2 + \sigma_Y^2}}} dx = \\
    %
    = \frac{1}{\sqrt{2 \pi} \sqrt{\sigma_X^2 + \sigma_Y^2}} \left ( \frac{1}{\sqrt{2 \pi} \frac{\sigma_X \sigma_Y}{\sqrt{\sigma_X^2 + \sigma_Y^2}}} \int \limits_{-\infty}^\infty e^{ - \frac{1}{2} \frac{\left ( x - A \right )^2}{\frac{\sigma_X^2 \sigma_Y^2}{\sigma_X^2 + \sigma_Y^2}}} dx \right ) e^{ -\frac{1}{2} \frac{ - A^2 + B}{\frac{\sigma_X^2 \sigma_Y^2}{\sigma_X^2 + \sigma_Y^2}}}= \\
    %
    = \frac{1}{\sqrt{2 \pi} \sqrt{\sigma_X^2 + \sigma_Y^2}} e^{ -\frac{1}{2} \frac{- A^2 + B}{\frac{\sigma_X^2 \sigma_Y^2}{\sigma_X^2 + \sigma_Y^2}}} .
\end{multline}
где показатель без $-\frac{1}{2}$ можно преобразовать к виду:
\begin{multline}
    \frac{- A^2 + B}{\frac{\sigma_X^2 \sigma_Y^2}{\sigma_X^2 + \sigma_Y^2}}
    = \frac{- \left ( \frac{\sigma_Y^2 m_X + \sigma_X^2 (z - m_Y)}{(\sigma_Y^2 + \sigma_X^2)} \right )^2 + \frac{\sigma_Y^2 m_X^2 + \sigma_X^2 (z - m_Y)^2}{(\sigma_Y^2 + \sigma_X^2)}}{\frac{\sigma_X^2 \sigma_Y^2}{\sigma_X^2 + \sigma_Y^2}} = \\
    %
    = \frac{- \frac{\sigma_Y^4 m_X^2 + 2 \sigma_Y^2 m_X^2 \sigma_X^2 (z - m_Y) + \sigma_X^4 (z - m_Y)^2}{(\sigma_Y^2 + \sigma_X^2)^2} + \frac{\sigma_Y^2 m_X^2 + \sigma_X^2 (z - m_Y)^2}{(\sigma_Y^2 + \sigma_X^2)}}{\frac{\sigma_X^2 \sigma_Y^2}{\sigma_X^2 + \sigma_Y^2}} = \\
    %
    = \frac{- \sigma_Y^4 m_X^2 - 2 \sigma_Y^2 m_X^2 \sigma_X^2 (z - m_Y) - \sigma_X^4 (z - m_Y)^2 + \left ( \sigma_Y^2 m_X^2 + \sigma_X^2 (z - m_Y)^2 \right ) (\sigma_Y^2 + \sigma_X^2)}{\sigma_X^2 \sigma_Y^2 \left ( \sigma_X^2 + \sigma_Y^2 \right )} = \\
    %
    = \frac{- 2 \sigma_Y^2 m_X^2 \sigma_X^2 (z - m_Y) + \sigma_X^2 \sigma_Y^2 m_X^2 + \sigma_X^2 \sigma_Y^2 (z - m_Y)^2}{\sigma_X^2 \sigma_Y^2 \left ( \sigma_X^2 + \sigma_Y^2 \right )} = \\
    %
    = \frac{- 2 m_X^2 (z - m_Y) + m_X^2 + (z - m_Y)^2}{\sigma_X^2 + \sigma_Y^2}
    = \frac{(z - m_Y)^2 - 2 (z - m_Y) m_X^2 + m_X^2}{\sigma_X^2 + \sigma_Y^2} = \\
    %
    = \frac{(z - m_Y - m_X)^2}{\sigma_X^2 + \sigma_Y^2} .
\end{multline}
Таким образом,
\begin{equation}
    f_Z(z)
    = \frac{1}{\sqrt{2 \pi} \sqrt{\sigma_X^2 + \sigma_Y^2}} e^{ -\frac{1}{2} \frac{(z - (m_X + m_Y))^2}{\sigma_X^2 + \sigma_Y^2}}
\end{equation}
и величина $Z$ имеет распределение $\mathcal{N} \left ( m_X + m_Y, \sigma_X^2 + \sigma_Y^2 \right )$.

Устойчивость можно доказать с помощью характеристических функций. Пусть $E_X(t)$ и $E_Y(t)$ --- характеристические функции случайных величин $X$ и $Y$:
\begin{gather}
    E_X(t) =  e^{m_X t - \frac{1}{2} \sigma_X^2 t^2} , \\
    E_Y(t) =  e^{m_Y t - \frac{1}{2} \sigma_Y^2 t^2} .
\end{gather}
Поскольку $X$ и $Y$ независимы, то характеристическая фукнция $E_Z(t)$:
\begin{equation}
    E_Z(t)
    = E_X(t) \cdot E_Y(t)
    = e^{m_X t - \frac{1}{2} \sigma_X^2 t^2} \cdot e^{m_Y t - \frac{1}{2} \sigma_Y^2 t^2}
    = e^{\left ( m_X + m_Y \right ) t - \frac{1}{2} \left ( \sigma_X^2 + \sigma_Y^2 \right ) t^2} .
\end{equation}
Легко видеть, что полученная характеристическая функция соответствует распределению $\mathcal{N} \left ( m_X + m_Y, \sigma_X^2 + \sigma_Y^2 \right )$.

\section*{Задачи для самостоятельного решения}

Из раздела 18 сборника задач Ефимова и Поспелова.
\begin{enumerate}
    \item На занятии: 445, 459.
    \item Дома: 439, 440, 453, 454, 464, 514, 522, 527, 531, 536, 537.
\end{enumerate}

Из сборника задач типового расчёта Чудесенко: 29, 30.
